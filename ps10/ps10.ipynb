{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All). Your code should run from top to bottom with no errors. Failure to do this will result in loss of points.\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\" and delete the `stop()` functions, as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\"  # your uniqname \n",
    "COLLABORATORS = c()  # vector of uniqnames of your collaborators, if any\n",
    "## IMPORTANT: also enter your group information in Canvas when you upload the assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f806389838eeb4c891f9db33c2c8cda7",
     "grade": false,
     "grade_id": "cell-892bf1ae756bcb37",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(modelr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "dd33e61e5ffb53c6cc743c65bf96a0f4",
     "grade": false,
     "grade_id": "cell-f73c39701a1d2ed0",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# STATS 306\n",
    "## Problem set 10: The end\n",
    "Each part of each problem is worth two to four points, depending on difficulty, for a total of 20.\n",
    "\n",
    "*Note*: you do not need to use `install.packages()` in this notebook. You may assume that we have already installed all of the necessary packages when we run your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "fb1e3ed0f1eeebb07b401906fab2302d",
     "grade": false,
     "grade_id": "cell-9e6d730e76d4355a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Problem 1 (2 pts.)\n",
    "If we regress `y` on `x`, then the regression coefficient gives the average rate of change of `y` with respect to `x`. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6e67f1aefa318d8cb0b2d81b78763c44",
     "grade": false,
     "grade_id": "cell-32c23065a1f25fc4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "lm(cty ~ hwy, mpg) %>% coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "66aac69913943b32e569c875e22ce49f",
     "grade": false,
     "grade_id": "cell-c54d1866f02177d8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "This says that if highway mileage increases by one mile per gallon, average city mileage increases by about 0.68 miles per gallon, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "dead62847c47af47b241111c76a43d9a",
     "grade": false,
     "grade_id": "cell-9a94060cdde7d46c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "dcity = mpg %>% filter(hwy %in% 24:25) %>% \n",
    "                group_by(hwy) %>% summarize(mean(cty)) %>% print\n",
    "diff(dcity[[2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "fbcef09946a1e741e79f09bb7a682c6f",
     "grade": false,
     "grade_id": "cell-e2220bfe5829bc2c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "In class we saw that `log(price)` has approximately a linear relationship with `log(carat)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "286f7813a5196d461711bd5bcdb9df58",
     "grade": false,
     "grade_id": "cell-064a0ab5a5cd8379",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "lm(log(price) ~ log(carat), diamonds) %>% coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "306af6dc60cd35e93b35484021cdf3fb",
     "grade": false,
     "grade_id": "cell-d21ef9969df8b0b1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "What does this regression say about the relationship between __price__ (not `log(price)`) and __carat__ (not `log(carat)`)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "5e23ba89c5b24e1ffb03a7bfc070557f",
     "grade": true,
     "grade_id": "cell-0ad01704f1f557d6",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8c6e52234c1436b47ff4700a1ab1ec8c",
     "grade": false,
     "grade_id": "cell-768d9201fc2fac0c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Problem 2 (2 pts.)\n",
    "In lecture we said that regressing `log(price)` on `log(carat)` \"removed\" the effect of size on a diamond's price, enabling us to visualize net effect of cut, color, and clarity on price by looking at the residuals of that regression.\n",
    "\n",
    "If the residuals are not affected by `log(carat)`, then intuitively they should be uncorrelated with `log(carat)`. Verify that this is true by computing the correlation between the residuals and the size predictor in this regression. Due to numerical error it will be very small but not exactly zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "49d5066f37239e686dc24bb6f0463f0f",
     "grade": true,
     "grade_id": "cell-8bff9fb6f94593da",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "79fe3546d94e143f39be61ca915efb79",
     "grade": false,
     "grade_id": "cell-2bf29ee97e2ef4e6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Explain why this implies that the predicted values are also uncorrelated with the residuals in a linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "57d4fd0793711878a9c411ab136755a1",
     "grade": true,
     "grade_id": "cell-f20b6ff093ff4e88",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6d307e756ebee58658a9d39a49fe0fd6",
     "grade": false,
     "grade_id": "cell-96b4568e5c3b34d3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Problem 3 (4 pts.)\n",
    "The standard error of a regression coefficient measures how much that estimate varies if we were to run the same data experiment many times and repeatedly re-fit a linear model. For example, suppose we get data from the following experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d54644871dd3eb5f21c24b5dc1ecfb32",
     "grade": false,
     "grade_id": "cell-363d7c35e1d725a1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "experiment = function() {\n",
    "    tibble(\n",
    "        x1 = rexp(rate = 10, n = 100),\n",
    "        x2 = rnorm(n = 100),\n",
    "        y = 3 * x1 - 2 * x2 + rnorm(n = 100, sd = .1)\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "96d932a3ff3ccca729a25e47b0eba400",
     "grade": false,
     "grade_id": "cell-84a3be38174bc4de",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "If we regress `y` on `x1` and `x2`, the standard error of `x1` coefficient in estimated to be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "41ffc1518432906034461a6bb2b49b6d",
     "grade": false,
     "grade_id": "cell-a7fee9140793018e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "experiment_data = experiment()\n",
    "lm(y ~ x1 + x2, experiment_data) %>% summary %>% coef %>% .['x2', 'Std. Error']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6518f6ebc755a0d9ad296a8d7fa8c474",
     "grade": false,
     "grade_id": "cell-7c5a3e88aa3e93a9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "We can verify that this is (approximately) correct by repeatedly running the experiment, fitting the linear model, and computing the standard error of the resulting estimates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f4c9b93aa210aa90d821f328544fd0ca",
     "grade": false,
     "grade_id": "cell-a4693399920cae45",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "extract_coef = function(df) lm(y ~ x1 + x2, df) %>% coef %>% .['x2'] \n",
    "map(1:1000, ~ experiment()) %>% map_dbl(extract_coef) %>% sd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4bbfe4a35b7ddaaba5f1fc86aa1c5542",
     "grade": false,
     "grade_id": "cell-355b05d9d36d2f23",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Of course, in real life, we usually do not have the luxury of generating as many new data sets as we want; we just have a single data set. A famous idea in statistics is to use just our one data set to generate many new data sets by sampling the observations with replacement. This is called \"[bootstrapping][1]\"; starting with just one data set we \"pull ourselves up by our bootstraps\".\n",
    "\n",
    "[1]: https://en.wikipedia.org/wiki/Bootstrapping_(statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d35ac2586f8abcedd74fb5bd2a9e177e",
     "grade": false,
     "grade_id": "cell-2f41f47e1c4b720d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**(2 pts.)** Write a function `bootstrap_df(df)` which, given a data frame containing `n` rows, returns a new data frame containing `n` rows sampled randomly _with replacement_ from `df`. (The \"with replacement\" part is important for obvious reasons.) For example, if\n",
    "```{r}\n",
    "df = tribble(\n",
    "    ~x, ~y,\n",
    "    1,   2,\n",
    "    3,   4,\n",
    "    5,   6\n",
    ")\n",
    "```\n",
    "then `bootstrap_df(df)` might return:\n",
    "\n",
    "```{r}\n",
    "  x y\n",
    "1 1 2\n",
    "2 1 2\n",
    "3 3 4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "55917cb2c852711707d88774e29b6bc4",
     "grade": false,
     "grade_id": "cell-ec737ca5706fbedb",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "bootstrap_df = function(df) {\n",
    "    # YOUR CODE HERE\n",
    "    stop()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "716eab63a35cdbe16cbfee68c933f08c",
     "grade": true,
     "grade_id": "cell-7ee57264e3e796af",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "bs = bootstrap_df(sim1)\n",
    "stopifnot(nrow(bs) == nrow(sim1))\n",
    "bs = bootstrap_df(tibble(x = rep(1, 100)))\n",
    "stopifnot(bs$x == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1bfa76f0d956781c3f4afbf98b0ae2b6",
     "grade": false,
     "grade_id": "cell-65b7985d62b9a936",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Use `bootstrap_df` to generate 1000 bootstrap replicates from `experiment_df` defined above, and use them to verify that the standard error of the `x2` regression coefficient is again $\\approx 0.01$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a04a3a6677942dbb570cc6d87eff7360",
     "grade": true,
     "grade_id": "cell-7743ffbe788c26c6",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "42ded4976b2b36867e35cec5029cf41f",
     "grade": false,
     "grade_id": "cell-e1433195e1e94b54",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Notice that the bootstrap is very general: nothing about it is specific to linear regression. This is why it is so popular, because it lets us estimate uncertainty in more complicated models where (unlike regression) we don't have  exact formulas for the standard error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2b49dd4db62ace09b12a6af6d7afc8f9",
     "grade": false,
     "grade_id": "cell-2dd354d2c78b7bb2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Problem 4 (8 pts.)\n",
    "In lecture we looked at a few examples of variable (a.k.a. model) selection: given a response variable, and some predictors, we studied residual plots in order to understand which predictors should be added to the model.\n",
    "\n",
    "This procedure works okay for small data sets, but quickly becomes unmanageable on larger data sets. Already with ten predictors, there are $2^{10} = 1024$ different linear models that we could fit (not including interaction terms)! So, on real data, it is usually not possible to do model selection by hand. Some sort of automated procedure is needed.\n",
    "\n",
    "------\n",
    "\n",
    "In this problem you will implement one such procedure, known as *all subsets regression*. The idea is simple: given a response variable $y$ and predictors $x_1, \\dots, x_p$, we fit all possible linear models involving $y$ and different combinations of the $x_i$. For each fitted model we record some measure of the quality of the fit. We select the model that has the highest quality score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a08274d2c292320fa87ae9f571a403c1",
     "grade": false,
     "grade_id": "cell-73f042329e24d260",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**(6 pts.)** Write a function `all_subsets_reg(df, qual)` which takes a data frame `df` and a function `qual` and implements all-subsets regression. The function `qual(mod)` takes as input a fitted model, and returns a quality score; higher scores are better. You may assume that the first column of `df` is the response variable, and the remaining columns of `df` are potential predictors. \n",
    "\n",
    "The function should return a vector containing the indices of the predictors that were selected under the best model. For example, if `df` is a tibble with four columns `y`, `x1`, `x2` and `x3`, and the algorithm selects `y ~ x1 + x3` as the best model, the `all_subsets(df, qual)` should return the vector `c(1, 3)`. \n",
    "\n",
    "If you want a more detailed description of how the algorithm should work, see the notebook [all_subsets_demo.ipynb](all_subsets_demo.ipynb) in this folder.\n",
    "\n",
    "(*Hint*: the `combn(v, k)` function can be used to return all subsets of the vector `v` of size `k`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "ebcb2ddf80879e74c2f3a87be9962a30",
     "grade": false,
     "grade_id": "cell-1980efd69057697c",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "all_subsets_reg = function(df, qual) {\n",
    "    # YOUR CODE HERE\n",
    "    stop()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "65847e71dc67d46383b52b4730ac9e33",
     "grade": false,
     "grade_id": "cell-be947bed0bea73d6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "The measure of model quality we will use is [AIC](https://en.wikipedia.org/wiki/Akaike_information_criterion). You don't need to understand how AIC works, but you should know that lower scores of AIC indicate a better model fit. Hence, we define our quality function to be:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0da31758407c1a4b3263343be17fe145",
     "grade": false,
     "grade_id": "cell-9b668d5601dfeb61",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "qual_aic = function(mdl) -AIC(mdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "003beb6b2632d7ef41088088dbe27f0c",
     "grade": true,
     "grade_id": "cell-c80326a3ca3e6b3a",
     "locked": true,
     "points": 6,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "# if there are no predictors, return empty vector\n",
    "stopifnot(is.null(all_subsets_reg(tibble(y = 1:10), qual_aic)))\n",
    "# x perfectly predicts y, so of course we include it\n",
    "stopifnot(identical(all_subsets_reg(tibble(y = 1:10, x = y), qual_aic), 1L))\n",
    "# x2 is nearly co-linear with x1, so we do not include it.\n",
    "stopifnot(identical(all_subsets_reg(tibble(y = 1:10, \n",
    "                                           x1 = y, \n",
    "                                           x2 = x1 + rnorm(n = 10)),\n",
    "                                    qual_aic), 1L))\n",
    "# if intercept-only model is selected, again return NULL\n",
    "stopifnot(is.null(all_subsets_reg(tibble(y = 1:10, x = rnorm(n = 10)), qual_aic)))\n",
    "# highway data\n",
    "df = sim4 %>% select(y, everything()) \n",
    "stopifnot(setequal(all_subsets_reg(df, qual_aic), c(1, 2)))\n",
    "# iris data\n",
    "data(iris)\n",
    "stopifnot(setequal(all_subsets_reg(iris, qual_aic), 1:4))\n",
    "# diamonds data are too big, take subset\n",
    "df = slice(diamonds, 1:1000) %>% select(price, everything())\n",
    "stopifnot(setequal(all_subsets_reg(df, qual_aic), c(2, 5, 6, 7, 8, 9)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "802b60ff525992cb9e89f60aa9438fb4",
     "grade": false,
     "grade_id": "cell-bbc441db6d783e79",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**(2 pts.)** Suppose that instead of AIC we had chosen $R^2$ as our measure of model quality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "dc16559a935ed1e1976f9f0c9d8f2998",
     "grade": false,
     "grade_id": "cell-7f58678018fad0f9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "qual_R2 = function(mdl) summary(mdl)$r.squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8f4da5541c72f9c00bb9dcd2a7c43def",
     "grade": false,
     "grade_id": "cell-bcac1c9dd09fb752",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Try running `all_subsets_reg(df, qual_R2)` for a few data sets. You should notice a pattern in terms of the variables that get selected. Explain why this pattern occurs. Is $R^2$ appropriate to use for model selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "dd48009a4d132d22eb3d12660dfb1487",
     "grade": true,
     "grade_id": "cell-1db1d481c975b22f",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f53183b178ba755359e0b86d20660ee6",
     "grade": false,
     "grade_id": "cell-5c041b7bf1baa08f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### Problem 5 (4 pts.)\n",
    "The previous problem studied variable selection. Why is variable selection necessary at all? Shouldn't we use all the available data, rather than adding only a subset of the predictors to our model? \n",
    "\n",
    "One argument for using fewer variables is parsimony: as we discussed in lecture, simpler models are more interpretable. However, even if we do not care about interpretability, there is another reason for preferring less complex models. In this problem, we will see that reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ce5ed303c1d92c335c02e42d0559bdfe",
     "grade": false,
     "grade_id": "cell-3f3dd1c588a3156a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**(2 pt.)** Write a function `split_data(df, p)` which, given a data frame `df` and a number $p \\in (0, 1)$, returns a list with two named elements, `train` and `test`. The function will randomly sample  (without replacement) $100 \\times p \\%$ of the rows (rounded to the nearest integer) from `df` and assign them to `train`. The remaining rows will be stored in `test`. For example, if `df` is a tibble with 100 rows and two columns then\n",
    "```{r}\n",
    "> split_data(df, p)\n",
    "$train\n",
    "# A tibble: 50 x 2\n",
    "<...>\n",
    "$test\n",
    "# A tibble: 50 x 2\n",
    "<...>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "7322aaa9e2d0cac8e6f5aafaaefca278",
     "grade": false,
     "grade_id": "cell-8ead8e2b94131a9a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "split_data = function(df, p) {\n",
    "    # YOUR CODE HERE\n",
    "    stop()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "198ca74a0d4c3ae8f497e48938222f66",
     "grade": true,
     "grade_id": "cell-09760af7622a6f33",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "stopifnot(nrow(split_data(sim1, .5)$train) == 15)\n",
    "stopifnot(nrow(split_data(sim1, .5)$test) == 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3a902cb80f76fe649a4b80dd48b05cc5",
     "grade": false,
     "grade_id": "cell-17927acd0860efdc",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**(1 pt.)** Next, write a function `ssr(df, mod)` which, given a data frame `df` and a model `mod`, returns the sum of squared residuals obtained by applying `mod` to `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "017367a39baf85720375dbcb5d1ff801",
     "grade": false,
     "grade_id": "cell-40e7f95fff907be2",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "ssr = function(df, mod) {\n",
    "    # YOUR CODE HERE\n",
    "    stop()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "53a8576c212d0c5e64f8b4f2e501560f",
     "grade": true,
     "grade_id": "cell-9d04eec35f808a2b",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "stopifnot(near(ssr(sim1, lm(y ~ x, sim1)), 135.8746, tol=1e-1))\n",
    "stopifnot(near(ssr(sim4, lm(y ~ x1 + x2, sim4)), 1322.714, tol=1e-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "733ba4b0e3d9da70aba83f2a5162bc75",
     "grade": false,
     "grade_id": "cell-d32c8fc6a29cbaf5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now we will split the `diamonds` into two halves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "df = split_data(diamonds, .5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9f4c60a48092d27ad3355ffe69532b3e",
     "grade": false,
     "grade_id": "cell-995fb1882b5d63b0",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "On the training data we will fit two models. The first is `log(price) ~ log(carat)` which we saw in lecture. The second, `log(price) ~ log(carat) + .^2`, contains hundreds more interaction terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3530743cc0a099546d6836631a57599c",
     "grade": false,
     "grade_id": "cell-8ceffc0525650c41",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "mod1 = lm(log(price) ~ log(carat), df$train)\n",
    "mod2 = lm(log(price) ~ log(carat) + .^2, df$train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c31ca59945e42faf19eb2055118c4159",
     "grade": false,
     "grade_id": "cell-7042b0208600dba3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "`mod2` is a much better predictor of `log(price)` on the training data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f2bde6c2391a7289d52800dcda132e01",
     "grade": false,
     "grade_id": "cell-4bfaf456e139d2ed",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "ssr(df$train, mod1)\n",
    "ssr(df$train, mod2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "19c681fb9ef95453b0f6f061869e95bf",
     "grade": false,
     "grade_id": "cell-a12ff1f50f4de43a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "However, `mod2` does much *worse* if we compare them on the test data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "402d47cdc56bf949f9503d58b08844cb",
     "grade": false,
     "grade_id": "cell-3a3bedee86cd3cf8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "ssr(df$test, mod1)\n",
    "ssr(df$test, mod2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9534dd7899f2aef38b604d93242be196",
     "grade": false,
     "grade_id": "cell-7f0be1469c754fc0",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "This is called \"[overfitting](https://en.wikipedia.org/wiki/Overfitting)\". `mod2` has so many extra predictors that it can fit not only the actual patterns which are present in `df$train`, but also the random noise in that data. Since the noise is different in `df$test`, `mod2` does a worse job of predicting \"out of sample\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
